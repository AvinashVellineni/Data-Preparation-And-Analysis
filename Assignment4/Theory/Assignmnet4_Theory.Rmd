---
title: "Assignment4 Theory"
output: html_notebook
author: "Avinash Vellineni"
---
## Problem 1.1

### Question3
```{r}
p = seq(0, 1, 0.005)
gini = p * (1 - p) * 2
entropy = -(p *log(p) +(1 - p)*log(1 - p))
class.err = 1 - pmax(p, 1 - p)
matplot(p, cbind(gini, entropy, class.err), col = c("orange","green", "red"),ylab = "error",xlab = "Probability")
```

## Problem 1.2

### Question3

```{r}
x = cbind(c(1, 1, 0, 5, 6, 4), c(4, 3, 4, 1, 2, 0))
colnames(x) <- c("x1","x2")
x
```

#### Part a

```{r}
plot(x[,1],x[,2],xlab="x",ylab="y")
```


#### Part b

```{r}
set.seed(1)
class_labels = sample(2, nrow(x), replace=T)
class_labels
```



#### Part c

```{r}
centroid_class1 = c(mean(x[class_labels==1, 1]), mean(x[class_labels==1, 2]))
centroid_class2 = c(mean(x[class_labels==2, 1]), mean(x[class_labels==2, 2]))
centroid_class1
centroid_class2
```

```{r}
plot(x[,1], x[,2], col=(class_labels+2), pch=20, cex=2,xlab="x",ylab="y")
points(centroid_class1[1], centroid_class1[2], col=3, pch=4)
points(centroid_class2[1], centroid_class2[2], col=4, pch=4)
```




#### Part d

```{r}
euclid = function(a, b) {
  return(sqrt((a[1] - b[1])^2 + (a[2]-b[2])^2))
}
give_labels = function(x, centroid_class1, centroid_class2) {
  class_labels = rep(NA, nrow(x))
  for (i in 1:nrow(x)) {
    if (euclid(x[i,], centroid_class1) < euclid(x[i,], centroid_class2)) {
      class_labels[i] = 1
    } else {
      class_labels[i] = 2
    }
  }
  return(class_labels)
}
class_labels = give_labels(x, centroid_class1, centroid_class2)
class_labels
```


#### Part e


```{r}
labels = rep(-1, 6)
while (!all(labels == class_labels)) {
  labels = class_labels
  centroid_class1 = c(mean(x[class_labels==1, 1]), mean(x[class_labels==1, 2]))
  centroid_class2 = c(mean(x[class_labels==2, 1]), mean(x[class_labels==2, 2]))
  print(centroid_class1)
  print(centroid_class2)
  class_labels = give_labels(x,centroid_class1, centroid_class2)
}
```

```{r}
class_labels
```

  
#### Part e

```{r}
plot(x[,1], x[,2], col=(class_labels+2), pch=20, cex=2,xlab="x",ylab="y")
points(centroid_class1[1], centroid_class1[2], col=3, pch=4)
points(centroid_class2[1], centroid_class2[2], col=4, pch=4)
```


## Question 6

### Partc
```{r}
set.seed(1)
c1 = matrix(rnorm(50*1000), ncol=50)
c2= matrix(rnorm(50*1000), ncol=50)
PC = cbind(c1, c2)
PC[1,] = seq(-18, 18 - .36, .36)
```

```{r}
pca = prcomp(scale(PC))
summary(pca)$importance[,1]
```
As mentioned the first principle explains 9.91% of the variance


As per par B we wiil do A vs B
```{r}
PC = rbind(PC, c(rep(10, 50), rep(0, 50)))
pca = prcomp(scale(PC))
summary(pca)$importance[,1]
```
No there is a slight improvement in the variance of the first principle component. It explains 11.5% of the variance. So there is an improvement of 1.6%.
